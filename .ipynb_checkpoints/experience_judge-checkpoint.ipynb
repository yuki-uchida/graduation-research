{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data1 = pd.read_csv(\"./input_data_1.csv\",header=None).drop(0,axis=0).drop([0],axis=1)\n",
    "data2 = pd.read_csv(\"./input_data_2.csv\",header=None).drop(0,axis=0).drop([0],axis=1)\n",
    "\n",
    "texts = np.array(data1.iloc[2,:]) + np.array(data2.iloc[2,:]) # concat使う\n",
    "labels = np.array(data1.iloc[1,:]) + np.array(data2.iloc[1,:])\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      4.8\n",
       "2      2.0\n",
       "3      4.8\n",
       "4      4.9\n",
       "5      4.4\n",
       "6      4.7\n",
       "7      3.8\n",
       "8      4.5\n",
       "9      4.8\n",
       "10     4.8\n",
       "11     4.7\n",
       "12     3.2\n",
       "13     4.2\n",
       "14     4.4\n",
       "15     4.9\n",
       "16     2.5\n",
       "17     1.9\n",
       "18     4.9\n",
       "19     2.6\n",
       "20     2.0\n",
       "21     4.4\n",
       "22     4.6\n",
       "23     4.3\n",
       "24     3.5\n",
       "25     4.9\n",
       "26     2.5\n",
       "27     4.7\n",
       "28     3.5\n",
       "29     3.3\n",
       "30     3.2\n",
       "      ... \n",
       "121    4.7\n",
       "122    4.6\n",
       "123    4.1\n",
       "124    4.6\n",
       "125    3.8\n",
       "126    4.5\n",
       "127    2.6\n",
       "128    4.1\n",
       "129    4.4\n",
       "130    4.3\n",
       "131    4.3\n",
       "132    4.5\n",
       "133    4.1\n",
       "134    4.4\n",
       "135    4.1\n",
       "136    4.7\n",
       "137    4.8\n",
       "138    3.9\n",
       "139    4.6\n",
       "140    4.6\n",
       "141    3.1\n",
       "142    4.2\n",
       "143    4.5\n",
       "144    4.4\n",
       "145    3.6\n",
       "146    4.5\n",
       "147    4.6\n",
       "148    4.2\n",
       "149    4.5\n",
       "150    3.7\n",
       "Name: 2, Length: 150, dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = 25\n",
    "input_data = []\n",
    "for vector in data1.values:\n",
    "    context_vectors = vector\n",
    "    while(len(context_vectors)<input_length):\n",
    "        context_vectors = np.append(context_vectors,[np.full(200,-1)], axis=0)\n",
    "#     print(context_vectors)\n",
    "    input_data.append(context_vectors)\n",
    "output_data = data1.iloc[1]\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-62b9fc8f0a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# train_input_data, val_input_data, train_output_data, val_output_data = train_test_split(input_data,output_data,train_size=0.8, test_size=0.2,random_state=42)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "input_data = np.array(input_data)\n",
    "output_data = np.array(output_data)\n",
    "# train_input_data, val_input_data, train_output_data, val_output_data = train_test_split(input_data,output_data,train_size=0.8, test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "# print(input_data.shape)\n",
    "# print(output_data.shape)\n",
    "# print(len(data[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uchidayuki/Python/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f95fc85d2e17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mN_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mN_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_validation\u001b[0m \u001b[0;34m=\u001b[0m     \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras import backend as K \n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "N_train = int(len(input_data) * 0.8)\n",
    "N_validation = len(input_data) - N_train\n",
    "\n",
    "print(input_data.shape,output_data.shape, len(data[2]))\n",
    "X_train, X_validation, Y_train, Y_validation, row_train, row_validation = \\\n",
    "    train_test_split(input_data, output_data, data[2], test_size=N_validation)\n",
    "\n",
    "\n",
    "maxlen = 25\n",
    "'''\n",
    "モデル設定\n",
    "'''\n",
    "n_in = 200  \n",
    "n_hidden = 512\n",
    "n_out = 1\n",
    "\n",
    "\n",
    "def weight_variable(shape, name=None):\n",
    "    return np.random.normal(scale=.01, size=shape)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred): \n",
    "     return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden,\n",
    "               kernel_initializer=weight_variable,\n",
    "               input_shape=(maxlen, n_in)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(n_out, kernel_initializer=weight_variable))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# optimizer = Adam(lr=0.0010, beta_1=0.9, beta_2=0.999)\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "# model.compile(loss='mean_squared_error',optimizer=optimizer)\n",
    "model.compile(loss=root_mean_squared_error,\n",
    "              optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-50ad16603f78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#earlystoppingなし\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model.fit(X_train, Y_train,\n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "モデル学習\n",
    "'''\n",
    "epochs = 300\n",
    "batch_size = 100\n",
    "\n",
    "# model.fit(X_train, Y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_data=(X_validation, Y_validation),\n",
    "#           callbacks=[early_stopping])\n",
    "\n",
    "#earlystoppingなし\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_validation, Y_validation))\n",
    "\n",
    "\n",
    "# model.fit(X_train, Y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_data=(X_validation, Y_validation))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-367a4c5ca64e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test_vectors = np.array(test_vectors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for text, pred in zip(row_train, y_train_pred):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(text, pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# test_vectors = np.array(test_vectors)\n",
    "y_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_validation)\n",
    "# for text, pred in zip(row_train, y_train_pred):\n",
    "#     print(text, pred)\n",
    "\n",
    "for text, pred, ans in zip(row_validation, y_test_pred, Y_validation):\n",
    "    print(text, pred, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0b50a98ad20d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtest_wakati_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtest_wakati_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# test_wakati_text = \"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "出力を用いて予測\n",
    "'''\n",
    "# 元データの最初の一部だけ切り出し\n",
    "# model.predict()\n",
    "# input_data[3:10].shape\n",
    "\n",
    "test_text = [ \"昨日、バイトがあって、お客さんがたくさん来ました\",\"浅井さんは丁寧で、非常に優しい\",\"前にここに来たときは、大雪だったので、あまり楽しめませんでした\",\"宿は長野県にある\",\"この旅館は人気がある\",\"従業員の方々は非常に優しく、対応が丁寧です\",\"従業員の方々が優しかったです\",\"佐々木希が来たらしい\",\"料理がとっても美味しくて、最高でした！\",\"非常に景色と温泉が綺麗で、部屋の内装やアメニティが良く、非常に満足出来るものでした\"]\n",
    "test_wakati_text = []\n",
    "for text in test_text:\n",
    "    test_wakati_text.append(tokenize(text))\n",
    "\n",
    "# test_wakati_text = \"\"\n",
    "word_model = word2vec.Word2Vec.load(\"./word2vec/model/wiki.model\")\n",
    "test_vectors = []\n",
    "for wakati_text in test_wakati_text:\n",
    "    test_vector = []\n",
    "    for char in m.removeStoplist(wakati_text, []).split(\" \"):\n",
    "        try:\n",
    "            test_vector.append(word_model[char])\n",
    "        except KeyError:\n",
    "            test_vector.append(unknown_token)\n",
    "    test_vectors.append(np.array(test_vector))\n",
    "\n",
    "# test_vectors = np.array(test_vectors)\n",
    "input_length = 25\n",
    "input_test_data = []\n",
    "for test_vector in test_vectors:\n",
    "    context_vectors = test_vector\n",
    "    while(len(context_vectors)<input_length):\n",
    "        context_vectors = np.append(context_vectors,[np.full(200,-1)], axis=0)\n",
    "    input_test_data.append(context_vectors)\n",
    "input_test_data = np.array(input_test_data)\n",
    "\n",
    "\n",
    "test_predictions = model.predict(input_test_data)\n",
    "\n",
    "for pred, text in zip(test_predictions, test_text):\n",
    "    print(text, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
