{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uchidayuki/Python/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec.load(\"./word2vec/model/wiki.model\")\n",
    "import MeCab\n",
    "tagger = MeCab.Tagger('-Owakati')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_data = pd.read_csv(\"./some.csv\",encoding='cp932',header=None).drop(0,axis=0).drop(1,axis=1).drop(0,axis=1)\n",
    "columns0 = np.insert(df_data.iloc[0].values,0,\"keyword\") \n",
    "columns1 = np.insert(df_data.iloc[1].values,0,\"keyword\")\n",
    "columns2 = np.insert(df_data.iloc[2].values,0,\"keyword\")\n",
    "columns3 = np.insert(df_data.iloc[3].values,0,\"keyword\")\n",
    "columns4 = np.insert(df_data.iloc[4].values,0,\"keyword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./kikuchi_sotsuken/finish_info.csv\",header=None).drop(0,axis=0).drop([0,1,2,3],axis=1)\n",
    "retu = []\n",
    "for i in range(105):\n",
    "    if (i%2 == 0)and(i >=6):\n",
    "        retu.append(i)\n",
    "df = df.drop(retu,axis=1)\n",
    "columns = []\n",
    "for i in range(51):\n",
    "    if i == 0:\n",
    "        columns.append(\"keyword\")\n",
    "    else:\n",
    "        columns.append(i)\n",
    "df.columns = columns\n",
    "df0 = df[df[\"keyword\"] == \"0\"]\n",
    "df1 = df[df[\"keyword\"] == \"1\"]\n",
    "df2 = df[df[\"keyword\"] == \"2\"]\n",
    "df3 = df[df[\"keyword\"] == \"3\"]\n",
    "df4 = df[df[\"keyword\"] == \"4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./kikuchi_sotsuken/finish_2_info.csv\",header=None).drop(0,axis=0).drop([0,1,2,3],axis=1)\n",
    "retu = []\n",
    "for i in range(105):\n",
    "    if (i%2 == 0)and(i >=6):\n",
    "        retu.append(i)\n",
    "df = df.drop(retu,axis=1)\n",
    "columns = []\n",
    "for i in range(51):\n",
    "    if i == 0:\n",
    "        columns.append(\"keyword\")\n",
    "    else:\n",
    "        columns.append(i)\n",
    "df.columns = columns\n",
    "df2_0 = df[df[\"keyword\"] == \"0\"]\n",
    "df2_1 = df[df[\"keyword\"] == \"1\"]\n",
    "df2_2 = df[df[\"keyword\"] == \"2\"]\n",
    "df2_3 = df[df[\"keyword\"] == \"3\"]\n",
    "df2_4 = df[df[\"keyword\"] == \"4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uchidayuki/Python/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/uchidayuki/Python/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./kikuchi_sotsuken/finish_3_info.csv\",header=None).drop(0,axis=0).drop([0,1,2,3],axis=1)\n",
    "retu = []\n",
    "for i in range(105):\n",
    "    if (i%2 == 0)and(i >=6):\n",
    "        retu.append(i)\n",
    "df = df.drop(retu,axis=1)\n",
    "columns = []\n",
    "for i in range(51):\n",
    "    if i == 0:\n",
    "        columns.append(\"keyword\")\n",
    "    else:\n",
    "        columns.append(i)\n",
    "df.columns = columns\n",
    "df3_0 = df[df[\"keyword\"] == \"0\"]\n",
    "df3_1 = df[df[\"keyword\"] == \"1\"]\n",
    "df3_2 = df[df[\"keyword\"] == \"2\"]\n",
    "df3_3 = df[df[\"keyword\"] == \"3\"]\n",
    "df3_4 = df[df[\"keyword\"] == \"4\"]\n",
    "df3_2.loc[100] = [2, 5, 5, 4, 4, 5, 4, 4, 3, 1, 3, 3, 4, 4, 2, 5, 3, 4, 3, 4, 5, 5, 5, 2, 3, 3, 1, 2, 2, 2, 3, 1, 2, 4, 4, 2, 5, 4, 2, 2, 3, 5, 3, 4, 4, 5, 5, 3, 3, 4, 4]\n",
    "df3_2.loc[101] = [2, 5, 5, 4, 4, 5, 4, 4, 3, 1, 3, 3, 4, 4, 2, 5, 3, 4, 3, 4, 5, 5, 5, 2, 3, 3, 1, 2, 2, 2, 3, 1, 2, 4, 4, 2, 5, 4, 2, 2, 3, 5, 3, 4, 4, 5, 5, 3, 3, 4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0.columns = columns0\n",
    "df1.columns = columns1\n",
    "df2.columns = columns2\n",
    "df3.columns = columns3\n",
    "df4.columns = columns4\n",
    "df2_0.columns = columns0\n",
    "df2_1.columns = columns1\n",
    "df2_2.columns = columns2\n",
    "df2_3.columns = columns3\n",
    "df2_4.columns = columns4\n",
    "df3_0.columns = columns0\n",
    "df3_1.columns = columns1\n",
    "df3_2.columns = columns2\n",
    "df3_3.columns = columns3\n",
    "df3_4.columns = columns4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 連結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df0 = pd.concat([df0, df2_0, df3_0]).drop(\"keyword\",axis=1).reset_index(drop=True).astype(np.int64)\n",
    "result_df1 = pd.concat([df1, df2_1, df3_1]).drop(\"keyword\",axis=1).reset_index(drop=True).astype(np.int64)\n",
    "result_df2 = pd.concat([df2, df2_2, df3_2]).drop(\"keyword\",axis=1).reset_index(drop=True).astype(np.int64)\n",
    "result_df3 = pd.concat([df3, df2_3, df3_3]).drop(\"keyword\",axis=1).reset_index(drop=True).astype(np.int64)\n",
    "result_df4 = pd.concat([df4, df2_4, df3_4]).drop(\"keyword\",axis=1).reset_index(drop=True).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平均・分散算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df0_mean = pd.DataFrame(result_df0.mean()).T.round(1)\n",
    "result_df1_mean = pd.DataFrame(result_df1.mean()).T.round(1)\n",
    "result_df2_mean = pd.DataFrame(result_df2.mean()).T.round(1)\n",
    "result_df3_mean = pd.DataFrame(result_df3.mean()).T.round(1)\n",
    "result_df4_mean = pd.DataFrame(result_df4.mean()).T.round(1)\n",
    "\n",
    "keyword0_mean = pd.DataFrame(result_df0.mean().round(1)).T\n",
    "keyword0_std = pd.DataFrame(result_df0.std().round(1)).T\n",
    "keyword1_mean = pd.DataFrame(result_df1.mean().round(1)).T\n",
    "keyword1_std = pd.DataFrame(result_df1.std().round(1)).T\n",
    "keyword2_mean = pd.DataFrame(result_df2.mean().round(1)).T\n",
    "keyword2_std = pd.DataFrame(result_df2.std().round(1)).T\n",
    "keyword3_mean = pd.DataFrame(result_df3.mean().round(1)).T\n",
    "keyword3_std = pd.DataFrame(result_df3.std().round(1)).T\n",
    "keyword4_mean = pd.DataFrame(result_df4.mean().round(1)).T\n",
    "keyword4_std = pd.DataFrame(result_df4.std().round(1)).T\n",
    "\n",
    "\n",
    "keyword0 = pd.concat([keyword0_mean,keyword0_std])\n",
    "keyword0.index = [\"mean\", \"std\"]\n",
    "\n",
    "keyword1 = pd.concat([keyword1_mean,keyword1_std])\n",
    "keyword1.index = [\"mean\", \"std\"]\n",
    "\n",
    "keyword2 = pd.concat([keyword2_mean,keyword2_std])\n",
    "keyword2.index = [\"mean\", \"std\"]\n",
    "\n",
    "keyword3 = pd.concat([keyword3_mean,keyword3_std])\n",
    "keyword3.index = [\"mean\", \"std\"]\n",
    "\n",
    "keyword4 = pd.concat([keyword4_mean,keyword4_std])\n",
    "keyword4.index = [\"mean\", \"std\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分かち書き"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MeCab\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    wakati = MeCab.Tagger(\"-O wakati\")\n",
    "    wakati.parse(\"\")\n",
    "    words = wakati.parse(text)\n",
    "\n",
    "    # Make word list\n",
    "    if words[-1] == u\"\\n\":\n",
    "        words = words[:-1]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['久しぶり の お 泊り ディズニー で 利用 さ せ て いただき まし た が ほんとに お 手頃 な 価格 で 、 それ だけ で 満足 でし た ',\n",
       " '女性 の 方 でも 安心 です ',\n",
       " '2 人 で の 利用 な ので お 部屋 も お 広く 清潔 感 も あり ゆったり と 過ごす こと が でき まし た 、 また 利用 さ せ て いただき たい と 思い ます ',\n",
       " '当日 、 禁煙 ルーム へ の 変更 を お願い し た ところ 12 階 に ある とても 広い 部屋 に 案内 し て いただき まし た ',\n",
       " 'キングサイズ の ベット 、 リビング ルーム 、 トイレ 、 テレビ も 二 ヶ所 あり 、 大 満足 でし た ',\n",
       " '毎月 ２ 日間 、 友人 と ディズニー を 楽しん で おり ます ',\n",
       " 'ホテル まで は 駅 から も 徒歩 で ５ 分 くらい 行ける ので 便利 です ',\n",
       " '送迎 バス も 有る ので 当日 の 疲れ 具合 や 天候 を 加味 し て 利用 し て おり ます ',\n",
       " 'ホテル 内 に コンビニ も 有る ので お 水 等 を 購入 する こと も 出来 て 便利 です ',\n",
       " '今回 は スタンダード の 予約 でし た が … キャンセル が 出 た よう で グレード アップ し て いただき まし た ',\n",
       " '駐車 場 込み だっ た ので 、 とても 良かっ た です ',\n",
       " 'また 、 こちら の ホテル を 利用 し たい と 思い ます ',\n",
       " 'また 、 その ケーキ を 持っ て き て くださっ た 方 の 対応 が とても 紳士 的 で 素晴らしく 感激 し まし た ',\n",
       " 'お 部屋 も 三 人 部屋 で ベッド も すべて 大きく て 寝心地 は 満点 です ',\n",
       " 'お 風呂 は 窓 が あり 海 が 見え て 、 洗面 を 挟ん で シャワー 室 が あり 素敵 でし た ',\n",
       " '9 階 の 部屋 で 、 バルコニー から 下 を 見 たら 綺麗 な プール が 見え まし た ',\n",
       " '朝 10 時 から 多く の 方々 が 利用 さ れ て い まし た ',\n",
       " '吹き抜け に なっ て い て 、 とても 解放 感 が あり 、 明るく 、 チャペル など も 上 から 見え て 、 とても 贅沢 な 作り だ な と 思い まし た ',\n",
       " '久しぶり の クラブ リゾート でし た が 、 やっぱり 落ち着き ます ',\n",
       " '部屋 と バス ルーム は 、 十分 な ほど の 広 さ が あり ます ',\n",
       " 'ピンク の 外観 が 可愛い の と 吹き抜け の 明る さ と 開放 感 も 気に入っ て ます ',\n",
       " 'スタッフ の 皆さん も 感じ が いい ので 、 また 泊まり たい です ',\n",
       " 'ディズニーシー の パイレーツサマー 、 楽しかっ た です ',\n",
       " 'ディズニーランド の 後 泊 で 利用 し まし た ！ ３ 回 目 の 利用 でし た が いつも 変わら ず 「 使っ て 良かっ た ！ 」 と 思わ せ て 頂い て ます ',\n",
       " '当日 部屋 の グレード アップ を 無料 でし て 頂け お 部屋 に 大 満足 でし た ',\n",
       " '朝食 も バイキング を 頂き まし た が 、 子供 用 に カレー を 甘く し て 頂け たり 気づかい が 素晴らしかっ た です ',\n",
       " 'オフィシャルホテル の 中 で 、 全て の 面 において 安心 し て 予約 でき ます ',\n",
       " '今回 、 初めて 修学旅行 生 と 同宿 でし た が 、 一般 客 と の 同線 が 重なら ない よう きちんと 配慮 さ れ て い て さすが だ と 思い まし た ',\n",
       " 'スタッフ さん が 一 人 一 人 の 対応 、 笑顔 が 素敵 でし た ',\n",
       " '私 の お気に入り の ホテル として 使わ せ て 頂い て おり ます ',\n",
       " 'お 部屋 から 見える ランド や シー の 景色 を 眺め ながら 、 気分 は 最高 に MAX !! 私 にとって は 充電 の 場所 と なっ てる みたい です ',\n",
       " 'ただ 、 一つ だけ 気 に なる こと が あり まし た ので コメント さ せ て 頂き ます ',\n",
       " 'スリッパ な の です が 使い捨て 用 の もの が ある と とっても 嬉しい です ',\n",
       " 'ディズニー 周辺 で 喫煙 の お 部屋 を 探し て い て お 値段 手頃 だっ た こちら に 決め まし た ',\n",
       " 'ホテル で は 寝る だけ な ので 期待 し て い ませ ん でし た が フロント の 方 も 丁寧 で 、 グレード アップ し て いただけ た 事 も 嬉しかっ た です ',\n",
       " 'また お 泊まり ディズニー する 際 は 利用 し たい です ',\n",
       " 'ディズニーランド に 行く 為 に 、 家族 3 人 で の 女子 旅 でし た ',\n",
       " '朝食 バイキング は 、 品数 も 豊富 で シェフ の 手作り オムレツ は とても 美味しかっ た ',\n",
       " '洗面 所 と バス 、 トイレ が 別 な ので 朝 の 混雑 も 快適 に 過ごし まし た ',\n",
       " '舞浜 駅 から 、 シャトル バス で 5 分 の 近 さ 、 運転 士 さん の トーク も 楽しく あっ と 言う ま に ホテル に 到着 し ます ',\n",
       " '部屋 の 広 さ は トランク も 広げ られ て ちょうど よい です ね ！ ',\n",
       " '部屋 も 広く 、 パーク が 一望 できる お 部屋 に し て いただき まし た ',\n",
       " 'とても 綺麗 で ゆっくり でき た ので また 利用 し たい です ！ ',\n",
       " '舞浜 駅 に 行く に は 20 分 おき に 無料 バス が で て い て 便利 でし た ',\n",
       " '前 から 予約 さ せ て もらっ て た から か 豪華 な お 部屋 に なっ て て 嬉しかっ た です ！ ',\n",
       " 'リーズナブル な 価格 で 泊まれ て とても 満足 です ',\n",
       " '立地 が よく 、 電車 で 降り て から 荷物 を 預け て ユニバ に 行け た の が とても 便利 でし た ',\n",
       " 'ホテル の シャンプー 、 リンス も 使い 心地 が 良く て よかっ た です ',\n",
       " 'チェック アウト 後 に 朝 から usj に 行き まし た ',\n",
       " '荷物 を ロッカー に 預け なけれ ば なら ず 、 探し に 行こ う と 思っ て い た ところ 、 チェック アウト し た に も 関わら ず 、 無料 で 預かっ て くれ て とても 助かり まし た ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples0 = df0.columns[1:]\n",
    "texts0 = [tokenize(a) for a in samples0]\n",
    "samples1 = df1.columns[1:]\n",
    "texts1 = [tokenize(a) for a in samples1]\n",
    "samples2 = df2.columns[1:]\n",
    "texts2 = [tokenize(a) for a in samples2]\n",
    "samples3 = df3.columns[1:]\n",
    "texts3 = [tokenize(a) for a in samples3]\n",
    "samples4 = df4.columns[1:]\n",
    "texts4 = [tokenize(a) for a in samples4]\n",
    "\n",
    "texts4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec.load(\"./word2vec/model/wiki.model\")\n",
    "\n",
    "\n",
    "from Ocab import Ocab, Regexp\n",
    "c = Regexp()\n",
    "m = Ocab(target=[\"名詞\",\"動詞\",\"形容詞\",\"副詞\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unknown_token = np.random.randint(-1, 1, (200, 1))  #\n",
    "unknown_token = np.random.random_sample(200)\n",
    "word2vec_array0 = []\n",
    "for str in texts0:\n",
    "    word_vectors = []\n",
    "    for char in m.removeStoplist(str, []).split(\" \"):\n",
    "        try:\n",
    "            word_vectors.append(model[char])\n",
    "#             print('#{0}ok'.format(char))\n",
    "        except KeyError:\n",
    "#             print('#{0}vocabularry error'.format(char))\n",
    "            for c in tokenize(char).split(\" \"):\n",
    "                try:\n",
    "                    word_vectors.append(model[c])\n",
    "#                     print('#{0}ok'.format(c))\n",
    "                except KeyError:\n",
    "                    word_vectors.append(unknown_token)\n",
    "#                     print('#{0}vocabularry error'.format(c))\n",
    "    word2vec_array0.append(word_vectors)\n",
    "\n",
    "word2vec_array1 = []\n",
    "for str in texts1:\n",
    "    word_vectors = []\n",
    "    for char in m.removeStoplist(str, []).split(\" \"):\n",
    "        try:\n",
    "            word_vectors.append(model[char])\n",
    "#             print('#{0}ok'.format(char))\n",
    "        except KeyError:\n",
    "#             print('#{0}vocabularry error'.format(char))\n",
    "            for c in tokenize(char).split(\" \"):\n",
    "                try:\n",
    "                    word_vectors.append(model[c])\n",
    "#                     print('#{0}ok'.format(c))\n",
    "                except KeyError:\n",
    "                    word_vectors.append(unknown_token)\n",
    "#                     print('#{0}vocabularry error'.format(c))\n",
    "    word2vec_array1.append(word_vectors)\n",
    "\n",
    "word2vec_array2 = []\n",
    "for str in texts2:\n",
    "    word_vectors = []\n",
    "    for char in m.removeStoplist(str, []).split(\" \"):\n",
    "        try:\n",
    "            word_vectors.append(model[char])\n",
    "#             print('#{0}ok'.format(char))\n",
    "        except KeyError:\n",
    "#             print('#{0}vocabularry error'.format(char))\n",
    "            for c in tokenize(char).split(\" \"):\n",
    "                try:\n",
    "                    word_vectors.append(model[c])\n",
    "#                     print('#{0}ok'.format(c))\n",
    "                except KeyError:\n",
    "                    word_vectors.append(unknown_token)\n",
    "#                     print('#{0}vocabularry error'.format(c))\n",
    "    word2vec_array2.append(word_vectors)\n",
    "\n",
    "word2vec_array3 = []\n",
    "for str in texts3:\n",
    "    word_vectors = []\n",
    "    for char in m.removeStoplist(str, []).split(\" \"):\n",
    "        try:\n",
    "            word_vectors.append(model[char])\n",
    "#             print('#{0}ok'.format(char))\n",
    "        except KeyError:\n",
    "#             print('#{0}vocabularry error'.format(char))\n",
    "            for c in tokenize(char).split(\" \"):\n",
    "                try:\n",
    "                    word_vectors.append(model[c])\n",
    "#                     print('#{0}ok'.format(c))\n",
    "                except KeyError:\n",
    "                    word_vectors.append(unknown_token)\n",
    "#                     print('#{0}vocabularry error'.format(c))\n",
    "    word2vec_array3.append(word_vectors)\n",
    "\n",
    "\n",
    "word2vec_array4 = []\n",
    "for str in texts4:\n",
    "    word_vectors = []\n",
    "    for char in m.removeStoplist(str, []).split(\" \"):\n",
    "        try:\n",
    "            word_vectors.append(model[char])\n",
    "#             print('#{0}ok'.format(char))\n",
    "        except KeyError:\n",
    "#             print('#{0}vocabularry error'.format(char))\n",
    "            for c in tokenize(char).split(\" \"):\n",
    "                try:\n",
    "                    word_vectors.append(model[c])\n",
    "#                     print('#{0}ok'.format(c))\n",
    "                except KeyError:\n",
    "                    word_vectors.append(unknown_token)\n",
    "#                     print('#{0}vocabularry error'.format(c))\n",
    "    word2vec_array4.append(word_vectors)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>久しぶりのお泊りディズニーで利用させていただきましたがほんとにお手頃な価格で、それだけで満足でした</th>\n",
       "      <th>女性の方でも安心です</th>\n",
       "      <th>2人での利用なのでお部屋もお広く清潔感もありゆったりと過ごすことができました、また利用させていただきたいと思います</th>\n",
       "      <th>当日、禁煙ルームへの変更をお願いしたところ12階にあるとても広い部屋に案内していただきました</th>\n",
       "      <th>キングサイズのベット、リビングルーム、トイレ、テレビも二ヶ所あり、大満足でした</th>\n",
       "      <th>毎月２日間、友人とディズニーを楽しんでおります</th>\n",
       "      <th>ホテルまでは駅からも徒歩で５分くらい行けるので便利です</th>\n",
       "      <th>送迎バスも有るので当日の疲れ具合や天候を加味して利用しております</th>\n",
       "      <th>ホテル内にコンビニも有るのでお水等を購入することも出来て便利です</th>\n",
       "      <th>今回はスタンダードの予約でしたが…キャンセルが出たようでグレードアップしていただきました</th>\n",
       "      <th>...</th>\n",
       "      <th>部屋の広さは  トランクも広げられて  ちょうど よいですね！</th>\n",
       "      <th>部屋も広く、パークが一望できるお部屋にしていただきました</th>\n",
       "      <th>とても綺麗でゆっくりできたのでまた利用したいです！</th>\n",
       "      <th>舞浜駅に行くには20分おきに無料バスがでていて便利でした</th>\n",
       "      <th>前から予約させてもらってたからか豪華なお部屋になってて嬉しかったです！</th>\n",
       "      <th>リーズナブルな価格で泊まれてとても満足です</th>\n",
       "      <th>立地がよく、電車で降りてから荷物を預けてユニバに行けたのがとても便利でした</th>\n",
       "      <th>ホテルのシャンプー、リンスも使い心地が良くてよかったです</th>\n",
       "      <th>チェックアウト後に朝からusjに行きました</th>\n",
       "      <th>荷物をロッカーに預けなければならず、探しに行こうと思っていたところ、チェックアウトしたにも関わらず、無料で預かってくれてとても助かりました</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      久しぶりのお泊りディズニーで利用させていただきましたがほんとにお手頃な価格で、それだけで満足でした  女性の方でも安心です  \\\n",
       "mean                                                4.7         2.8   \n",
       "std                                                 0.5         0.9   \n",
       "\n",
       "      2人での利用なのでお部屋もお広く清潔感もありゆったりと過ごすことができました、また利用させていただきたいと思います  \\\n",
       "mean                                                4.7           \n",
       "std                                                 0.5           \n",
       "\n",
       "      当日、禁煙ルームへの変更をお願いしたところ12階にあるとても広い部屋に案内していただきました  \\\n",
       "mean                                             4.8   \n",
       "std                                              0.4   \n",
       "\n",
       "      キングサイズのベット、リビングルーム、トイレ、テレビも二ヶ所あり、大満足でした  毎月２日間、友人とディズニーを楽しんでおります  \\\n",
       "mean                                      4.8                      3.7   \n",
       "std                                       0.4                      1.1   \n",
       "\n",
       "      ホテルまでは駅からも徒歩で５分くらい行けるので便利です  送迎バスも有るので当日の疲れ具合や天候を加味して利用しております  \\\n",
       "mean                          3.2                               3.7   \n",
       "std                           0.8                               1.1   \n",
       "\n",
       "      ホテル内にコンビニも有るのでお水等を購入することも出来て便利です  \\\n",
       "mean                               3.8   \n",
       "std                                1.1   \n",
       "\n",
       "      今回はスタンダードの予約でしたが…キャンセルが出たようでグレードアップしていただきました  \\\n",
       "mean                                           4.3   \n",
       "std                                            0.8   \n",
       "\n",
       "                                      ...                                    \\\n",
       "mean                                  ...                                     \n",
       "std                                   ...                                     \n",
       "\n",
       "      部屋の広さは  トランクも広げられて  ちょうど よいですね！   部屋も広く、パークが一望できるお部屋にしていただきました  \\\n",
       "mean                               3.6                           4.1   \n",
       "std                                1.2                           0.8   \n",
       "\n",
       "      とても綺麗でゆっくりできたのでまた利用したいです！  舞浜駅に行くには20分おきに無料バスがでていて便利でした  \\\n",
       "mean                        4.3                           4.3   \n",
       "std                         1.0                           0.7   \n",
       "\n",
       "      前から予約させてもらってたからか豪華なお部屋になってて嬉しかったです！  リーズナブルな価格で泊まれてとても満足です  \\\n",
       "mean                                  4.4                    4.2   \n",
       "std                                   1.0                    1.0   \n",
       "\n",
       "      立地がよく、電車で降りてから荷物を預けてユニバに行けたのがとても便利でした  ホテルのシャンプー、リンスも使い心地が良くてよかったです  \\\n",
       "mean                                    4.4                           4.6   \n",
       "std                                     1.0                           0.7   \n",
       "\n",
       "      チェックアウト後に朝からusjに行きました  \\\n",
       "mean                    4.1   \n",
       "std                     1.1   \n",
       "\n",
       "      荷物をロッカーに預けなければならず、探しに行こうと思っていたところ、チェックアウトしたにも関わらず、無料で預かってくれてとても助かりました  \n",
       "mean                                                4.8                      \n",
       "std                                                 0.4                      \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##これが文章ベクトル 入力データ\n",
    "word2vec_array0\n",
    "word2vec_array1\n",
    "word2vec_array2\n",
    "word2vec_array3\n",
    "word2vec_array4\n",
    "##これが正解データ\n",
    "keyword0\n",
    "keyword1\n",
    "keyword2\n",
    "keyword3\n",
    "keyword4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [文章ベクトル,正解データ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [[],[],[]]\n",
    "for vec, label, row in zip(word2vec_array0, keyword0.loc[\"mean\"].values, samples0):\n",
    "    data[0].append(np.array(vec))\n",
    "    data[1].append(label)\n",
    "    data[2].append(row)\n",
    "for vec, label, row in zip(word2vec_array1, keyword1.loc[\"mean\"].values, samples1):\n",
    "    data[0].append(np.array(vec))\n",
    "    data[1].append(label)\n",
    "    data[2].append(row)\n",
    "for vec, label, row in zip(word2vec_array2, keyword2.loc[\"mean\"].values, samples2):\n",
    "    data[0].append(np.array(vec))\n",
    "    data[1].append(label)\n",
    "    data[2].append(row)\n",
    "for vec, label, row in zip(word2vec_array3, keyword3.loc[\"mean\"].values, samples3):\n",
    "    data[0].append(np.array(vec))\n",
    "    data[1].append(label)\n",
    "    data[2].append(row)\n",
    "for vec, label, row in zip(word2vec_array4, keyword4.loc[\"mean\"].values, samples4):\n",
    "    data[0].append(np.array(vec))\n",
    "    data[1].append(label)\n",
    "    data[2].append(row)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('input_data_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
